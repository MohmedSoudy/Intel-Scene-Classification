{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intel challenge for scene classification\n",
    "#Challenge link: https://datahack.analyticsvidhya.com/contest/practice-problem-intel-scene-classification-challe/\n",
    "#DataSet link: https://www.kaggle.com/nitishabharathi/scene-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load required packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os,shutil\n",
    "from tensorflow.keras import models,layers,optimizers, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.jpg</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name   label\n",
       "0      0.jpg    Real\n",
       "1      1.jpg  Nature\n",
       "2      2.jpg    Real\n",
       "3      4.jpg    Real\n",
       "4      7.jpg  Nature"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading train data\n",
    "df= pd.read_csv(\"train.csv\")\n",
    "#df = df.replace(0,'buildings').replace(1,'forest').replace(2,'glacier').replace(3,'mountain').replace(4,'sea').replace(5,'street')\n",
    "df = df.replace(0,'Real').replace(1,'Nature').replace(2,'Nature').replace(3,'Nature').replace(4,'Nature').replace(5,'Real')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RSH\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\RSH\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:356: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13628 validated image filenames belonging to 2 classes.\n",
      "Found 3406 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image Augmentation using keras ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                           #shear_range = 0.15,\n",
    "                           #zoom_range = 0.15,\n",
    "                           horizontal_flip=False,\n",
    "                           preprocessing_function= preprocess_input,\n",
    "                           featurewise_std_normalization=True,\n",
    "                           samplewise_std_normalization=True,\n",
    "                           fill_mode=\"constant\",\n",
    "                           validation_split=0.20)\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=df,\n",
    "                        directory=\"train/\",\n",
    "                        x_col=\"image_name\",\n",
    "                        y_col=\"label\",\n",
    "                        subset=\"training\",\n",
    "                        batch_size=500,\n",
    "                        seed=42,\n",
    "                        shuffle=True,\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(228,228))\n",
    "valid_generator = datagen.flow_from_dataframe(dataframe=df,\n",
    "                        directory=\"train/\",\n",
    "                        x_col=\"image_name\",\n",
    "                        y_col=\"label\",\n",
    "                        subset=\"validation\", batch_size=100,\n",
    "                        seed=42,\n",
    "                        shuffle=True,\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(228,228))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 228, 228, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 114, 114, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 114, 114, 64)      256       \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 57, 57, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 57, 57, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 57, 57, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 29, 29, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 225,666\n",
      "Trainable params: 224,770\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model construction \n",
    "def conv_bn(x):\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return layers.ReLU()(x)\n",
    "\n",
    "inputs = layers.Input(shape=(228,228, 3))\n",
    "x = conv_bn(inputs)\n",
    "x = conv_bn(x)\n",
    "x = conv_bn(x)\n",
    "x = conv_bn(x)\n",
    "x = conv_bn(x)\n",
    "x = conv_bn(x)\n",
    "x = conv_bn(x)\n",
    "\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer = optimizers.RMSprop(lr=0.01),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RSH\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "C:\\Users\\RSH\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\RSH\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 465s 17s/step - loss: 0.7785 - acc: 0.6429 - val_loss: 112.8748 - val_acc: 0.6771\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 412s 15s/step - loss: 0.4910 - acc: 0.7580 - val_loss: 171.6062 - val_acc: 0.6765\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 408s 15s/step - loss: 0.3765 - acc: 0.8351 - val_loss: 9.2411 - val_acc: 0.6741\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 414s 15s/step - loss: 0.3036 - acc: 0.8752 - val_loss: 6.1456 - val_acc: 0.4032\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 406s 15s/step - loss: 0.2968 - acc: 0.8724 - val_loss: 2.2558 - val_acc: 0.7826\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 411s 15s/step - loss: 0.1997 - acc: 0.9243 - val_loss: 0.5110 - val_acc: 0.8485\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 406s 15s/step - loss: 0.1748 - acc: 0.9351 - val_loss: 0.7043 - val_acc: 0.8226\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 409s 15s/step - loss: 0.1344 - acc: 0.9506 - val_loss: 0.9941 - val_acc: 0.8559\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 406s 15s/step - loss: 0.1283 - acc: 0.9542 - val_loss: 3.5925 - val_acc: 0.6747\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 408s 15s/step - loss: 0.1437 - acc: 0.9481 - val_loss: 0.8866 - val_acc: 0.8044\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 561s 21s/step - loss: 0.1279 - acc: 0.9542 - val_loss: 0.9933 - val_acc: 0.7829\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 576s 21s/step - loss: 0.0902 - acc: 0.9668 - val_loss: 1.6868 - val_acc: 0.8121\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 632s 23s/step - loss: 0.0895 - acc: 0.9674 - val_loss: 0.1673 - val_acc: 0.9438\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 529s 19s/step - loss: 0.0988 - acc: 0.9643 - val_loss: 0.1301 - val_acc: 0.9535\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 383s 14s/step - loss: 0.0646 - acc: 0.9768 - val_loss: 0.1431 - val_acc: 0.9479\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 390s 14s/step - loss: 0.0549 - acc: 0.9806 - val_loss: 0.1580 - val_acc: 0.9506\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 408s 15s/step - loss: 0.0491 - acc: 0.9831 - val_loss: 0.1441 - val_acc: 0.9515\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0477 - acc: 0.9835 - val_loss: 0.1661 - val_acc: 0.9512\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 414s 15s/step - loss: 0.0359 - acc: 0.9869 - val_loss: 0.1957 - val_acc: 0.9500\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 390s 14s/step - loss: 0.0321 - acc: 0.9889 - val_loss: 0.1477 - val_acc: 0.9506\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 399s 15s/step - loss: 0.0323 - acc: 0.9877 - val_loss: 0.1844 - val_acc: 0.9594\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 391s 14s/step - loss: 0.0187 - acc: 0.9933 - val_loss: 0.1697 - val_acc: 0.9550\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 386s 14s/step - loss: 0.0320 - acc: 0.9871 - val_loss: 0.1497 - val_acc: 0.9621\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 391s 14s/step - loss: 0.0149 - acc: 0.9951 - val_loss: 0.1637 - val_acc: 0.9624\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 0.0265 - acc: 0.9918 - val_loss: 0.4695 - val_acc: 0.9168\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0201 - acc: 0.9934 - val_loss: 0.1532 - val_acc: 0.9712\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 398s 15s/step - loss: 0.0129 - acc: 0.9952 - val_loss: 0.1890 - val_acc: 0.9574\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 396s 15s/step - loss: 0.0103 - acc: 0.9964 - val_loss: 0.2335 - val_acc: 0.9435\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0151 - acc: 0.9946 - val_loss: 0.1734 - val_acc: 0.9671\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 409s 15s/step - loss: 0.0176 - acc: 0.9954 - val_loss: 0.2036 - val_acc: 0.9641\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 400s 15s/step - loss: 0.0092 - acc: 0.9968 - val_loss: 0.4950 - val_acc: 0.9368\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 396s 15s/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.4888 - val_acc: 0.9503\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.2867 - val_acc: 0.9532\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 398s 15s/step - loss: 0.0109 - acc: 0.9975 - val_loss: 0.2153 - val_acc: 0.9644\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0084 - acc: 0.9975 - val_loss: 0.2498 - val_acc: 0.9532\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 399s 15s/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.1876 - val_acc: 0.9685\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 395s 15s/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.2238 - val_acc: 0.9576\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 395s 15s/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.2692 - val_acc: 0.9418\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 0.0066 - acc: 0.9977 - val_loss: 0.3308 - val_acc: 0.9438\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.2880 - val_acc: 0.9565\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 395s 15s/step - loss: 0.0106 - acc: 0.9959 - val_loss: 0.2599 - val_acc: 0.9612\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.2681 - val_acc: 0.9624\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 398s 15s/step - loss: 0.0118 - acc: 0.9969 - val_loss: 0.2086 - val_acc: 0.9662\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 395s 15s/step - loss: 0.0145 - acc: 0.9952 - val_loss: 0.2598 - val_acc: 0.9682\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 396s 15s/step - loss: 0.0047 - acc: 0.9979 - val_loss: 0.2540 - val_acc: 0.9656\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 393s 15s/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.3225 - val_acc: 0.9629\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 396s 15s/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.3201 - val_acc: 0.9612\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 463s 17s/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.2244 - val_acc: 0.9615\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 518s 19s/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.3231 - val_acc: 0.9576\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 534s 20s/step - loss: 0.0160 - acc: 0.9954 - val_loss: 0.2039 - val_acc: 0.9679\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 558s 21s/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.2802 - val_acc: 0.9503\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 738s 28s/step - loss: 0.0087 - acc: 0.9976 - val_loss: 0.2736 - val_acc: 0.9656\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 33218s 1277s/step - loss: 0.0013 - acc: 0.9994 - val_loss: 0.8077 - val_acc: 0.9088\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 543s 19s/step - loss: 0.0183 - acc: 0.9947 - val_loss: 0.3201 - val_acc: 0.9585\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 403s 15s/step - loss: 0.0056 - acc: 0.9978 - val_loss: 0.7086 - val_acc: 0.9129\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.4130 - val_acc: 0.9624\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 406s 15s/step - loss: 0.0048 - acc: 0.9982 - val_loss: 0.3039 - val_acc: 0.9618\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 393s 15s/step - loss: 0.0065 - acc: 0.9973 - val_loss: 0.3460 - val_acc: 0.9638\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 385s 14s/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.3940 - val_acc: 0.9409\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 389s 14s/step - loss: 0.0029 - acc: 0.9988 - val_loss: 0.2755 - val_acc: 0.9624\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 388s 14s/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.2714 - val_acc: 0.9638\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 388s 14s/step - loss: 7.5793e-04 - acc: 0.9999 - val_loss: 0.2448 - val_acc: 0.9709\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 385s 14s/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.4073 - val_acc: 0.9556\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 389s 14s/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.5132 - val_acc: 0.9429\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 384s 15s/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.3252 - val_acc: 0.9609\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 389s 14s/step - loss: 0.0090 - acc: 0.9973 - val_loss: 0.4363 - val_acc: 0.9526\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 393s 15s/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.4311 - val_acc: 0.9535\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.2740 - val_acc: 0.9706\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 396s 15s/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.2571 - val_acc: 0.9676\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 393s 14s/step - loss: 8.9156e-04 - acc: 0.9998 - val_loss: 0.3491 - val_acc: 0.9568\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 2.0948e-04 - acc: 1.0000 - val_loss: 0.5058 - val_acc: 0.9376\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 0.0147 - acc: 0.9964 - val_loss: 0.3537 - val_acc: 0.9641\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.2978 - val_acc: 0.9638\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 400s 15s/step - loss: 0.0063 - acc: 0.9985 - val_loss: 0.3963 - val_acc: 0.9521\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 392s 14s/step - loss: 0.0122 - acc: 0.9976 - val_loss: 0.2833 - val_acc: 0.9635\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 393s 15s/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.5252 - val_acc: 0.9341\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 392s 14s/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.2547 - val_acc: 0.9671\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 395s 15s/step - loss: 6.4182e-04 - acc: 0.9999 - val_loss: 0.2451 - val_acc: 0.9668\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 391s 14s/step - loss: 0.0112 - acc: 0.9981 - val_loss: 1.1787 - val_acc: 0.8956\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 392s 14s/step - loss: 0.0215 - acc: 0.9976 - val_loss: 0.3529 - val_acc: 0.9671\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 390s 14s/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.4326 - val_acc: 0.9612\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 392s 14s/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.2412 - val_acc: 0.9674\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 393s 15s/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.3151 - val_acc: 0.9641\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 391s 14s/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.5816 - val_acc: 0.9594\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 396s 15s/step - loss: 6.9045e-04 - acc: 0.9998 - val_loss: 0.5483 - val_acc: 0.9438\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 390s 14s/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.3532 - val_acc: 0.9674\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.3093 - val_acc: 0.9650\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 400s 15s/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.3656 - val_acc: 0.9624\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 395s 15s/step - loss: 0.0023 - acc: 0.9990 - val_loss: 0.3347 - val_acc: 0.9626\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0100 - acc: 0.9971 - val_loss: 0.3079 - val_acc: 0.9600\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 396s 15s/step - loss: 6.0591e-04 - acc: 0.9998 - val_loss: 0.2467 - val_acc: 0.9715\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 396s 15s/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.6339 - val_acc: 0.9312\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 0.0086 - acc: 0.9978 - val_loss: 0.2824 - val_acc: 0.9653\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.3761 - val_acc: 0.9659\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 395s 15s/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.5691 - val_acc: 0.9538\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 396s 15s/step - loss: 0.0035 - acc: 0.9994 - val_loss: 0.3840 - val_acc: 0.9609\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 395s 15s/step - loss: 0.0017 - acc: 0.9993 - val_loss: 0.8234 - val_acc: 0.9274\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 394s 15s/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.5085 - val_acc: 0.9541\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 397s 15s/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.3089 - val_acc: 0.9659\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 408s 15s/step - loss: 0.0029 - acc: 0.9989 - val_loss: 0.7014 - val_acc: 0.9526\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "history =model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model, load_model\n",
    "model = model.save_weights(\"Binary model.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2120ebe6d687bd7269b14a072cb1f89440c016ed7b19acca32e0959bf7bfd92e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
